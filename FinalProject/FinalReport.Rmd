---
title: "FinalReport"
author: "Kathleen Cachel"
date: "5/28/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting TED Talk Views

```{r initialize, echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2) # Data visualisation
library(reshape2)
library(corrplot)
library(dplyr) 
library(ggthemes)
library(anytime)
library(lubridate)
library(ggpubr)
library(tm)
library(tidyverse)
TedRaw <- read.csv(file="ted_main.csv", header=TRUE, sep=",")

```

## Exploratory Data Analysis 

The TED Talk dataset contains entries for 2550 talks on the TED website and contains 17 variables (of which the predictor **views** is one). Some variables are useful as is and some require data munging or transformation. Below we work through the variables and outline their potential transformations. 

### Variable: comments
The variable **comments** is an interger denoting how many top level comments are posted to a talks site. Without knowing all that much it seems a reasonable hypothesis would be comments is a decent predictor of **views**.  

Below is a histogram graph binning TED talks by the number of comments on the talk's site. We can see the median (black) is left of the average (red), indicating it is right skewed. 

```{r eda comments}
#Number of Comments
#Histogram Graph
ggplot(data=TedRaw, aes(x=comments)) +
  geom_histogram(binwidth=50, fill = '#99d8c9')+
  geom_vline(aes(xintercept = mean(comments)),col='red',
             size=.5, linetype="dotted")+
  geom_vline(aes(xintercept = median(comments)),col='black',
             size=.5, linetype="dotted")+
  labs(x = "Number of Comments", y = "Count of TED Talks",
       title = "Histogram of Comments")+
  scale_x_continuous(breaks = pretty(TedRaw$comments, n = 22))
```


Below is a plot of the observation with **comments** on the X-axis and **views** on the Y-axis. We can see that the R value is 0.53 and the p value is significant. Based on this information, we will likely keep the **comments** variable in future models. 

```{r EDA cor comments}
ggscatter(TedRaw, x = "comments", y = "views", 
          add = "reg.line", conf.int = TRUE, color = "blue",
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "comments", ylab = "views")
```

### Variable: duration
The variable **duration** is an interger denoting how long a TED Talk is in seconds. Without knowing much we might assume that longer talks have less views since people may be less inclined to watch longer videos. 

Below is a histogram graph binning TED talks by their length.  We can see the median (black) is pretty close to the average (red). It looks like the majority of talks are under 1200 seconds, and the most are around 1000-1200.

```{r EDA duration}
#Duration of Talk
duration <- TedRaw %>%
  group_by(duration) %>%
  tally(name ="numTalks") 

#histogram
ggplot(data=TedRaw, aes(x=duration)) +
  geom_histogram(binwidth=50, fill = '#fa9fb5')+
  geom_vline(aes(xintercept = mean(duration)),col='red',
             size=.5, linetype="dotted")+
  geom_vline(aes(xintercept = median(duration)),col='black',
             size=.5, linetype="dotted")+
  labs(x = "Length of Talk (s)", y = "Count of TED Talks",
       title = "Histogram of Talk Length (s)")+
  scale_x_continuous(breaks = pretty(TedRaw$duration, n = 22))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


Is **duration** correlated with **views**? Not really.Below is a plot of the observation with **duration** on the X-axis and **views** on the Y-axis. We can see that the R value is pretty small (0.049) and the p value is significant. Based on this information, we will likely keep the **duration** variable in future models, but be mindful that it may have little effect.

```{r EDA cor duration}
ggscatter(TedRaw, x = "duration", y = "views", 
          add = "reg.line", conf.int = TRUE, color = "blue",
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "duration (s)", ylab = "views")
```


### Variable: languages
The variable **languages** is an integer denoting how manuy languages the talk is available to view in. Presumeably an increase in translations should increas views. 

In the graph below we can see that there is a fairly normal distribution for the number of languages. 
```{r}
languages <- TedRaw %>%
  group_by(languages) %>%
  tally(name ="numTalks") 


#Number of Languages
ggplot(data=languages, aes(x=languages, y=numTalks)) +
  geom_point(stat = "identity", aes(color = '#fa9fb5'))+
  #geom_bar(stat = "identity", fill = '#fa9fb5')+
  geom_vline(aes(xintercept = mean(TedRaw$languages)),col='red',
             size=.5, linetype="dotted")+
  geom_vline(aes(xintercept = median(TedRaw$languages)),col='black',
             size=.5, linetype="dotted")+
  labs(x = "Number of available languages", y = "Count of TED Talks",
       title = "Talks available in translated languages")+
  scale_x_continuous(breaks = pretty(TedRaw$languages, n = 20))
```


Is **languages** correlated with **views**? A little.. Below we can see that the R - value is 0.38 and is statistically significant. We will keep the variable in future models. 

### Variable: speaker_occupation
The variable **speaker_occupation** is the occupation of the main speaker. There are 1459 unique occupations. Below is a graph indicating the top 15 occupations. Since they make up 402 talks (16%) it could be worth exploring breaking the top 15 or 10 occupations into boolean predictors in a future model.


```{r EDA speaker occupation}
##speaker occupation
speaker_occupation <- TedRaw %>%
  group_by(speaker_occupation) %>%
  tally(name ="numTalks") 

speaker_occupationtop <- arrange(speaker_occupation, desc(numTalks))
speaker_occupationtop <- head(speaker_occupationtop,15)

ggplot(data=speaker_occupationtop, aes(x=speaker_occupation, y=numTalks)) +
  geom_bar(stat = "identity", fill = '#c51b8a')+
  geom_text(aes(label = numTalks), vjust = 1.6, color = "white", size = 3)+
  labs(x = "Speaker Occupation", y = "Count of TED Talks",
       title = "Talks by 15 most popular speaker occupations")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Variable: num_speaker
The variable **num_speaker** contains the number of speakers in the TED talk.In the graph below we can see the overwhelming majority of talks had 1 speaker. This isn't really an interesting metric and will likely not be included in future models. 

```{r}
ggscatter(TedRaw, x = "num_speaker", y = "views", 
          add = "reg.line", conf.int = TRUE, color = "blue",
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "number of speakers", ylab = "views")
```


### Variable: event
The variable **event** is the name of the TED event the TED Talk was given at. There are 355 unique events. Below is a graph showing the top events. Since they make up 1283 (50%) of the talks, there is potential to break this into boolean predictors. Something to be aware of is that the events mostly contain a year in the name so this variable could contain duplicate information as the **filmed_date** variable, so we would likely want to select only one to loop into future models.

```{r EDA event}
event <- TedRaw %>%
  group_by(event) %>%
  tally(name ="numTalks") 

eventtop <- arrange(event, desc(numTalks))
eventtop <- head(eventtop,20)
ggplot(data=eventtop, aes(x=event, y=numTalks)) +
  #geom_point(stat = "identity", aes(color = '#2b8cbe'))+
  geom_bar(stat = "identity", fill = '#c51b8a')+
  geom_text(aes(label = numTalks), vjust = 1.6, color = "white", size = 3)+
  labs(x = "Event", y = "Count of TED Talks",
       title = "Talks by 20 most popular Events")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Variable: film_date
The variable **film_date** is the date the TED Talk was filmed. Below is a plot of TED talks by their film date. We likely won't use *film_date** as predictor in favor of **event**.

```{r EDA filmed_date}
#film_date
film_date <- anydate(TedRaw$film_date)
TedRaw$film_date_clean <- film_date


film_date_clean <- TedRaw %>%
  group_by(film_date_clean) %>%
  tally(name ="numTalks") 

ggplot(data = film_date_clean, aes(x = film_date_clean, y = numTalks))+
  geom_line(color = "#feb24c")+
  labs(x = "Date", y = "Count of TED Talks",
       title = "Talks by film date")
```

### Variable: published_date
The variable **published_date** is the date the TED Talk was published to the TED website. Below are 3 graphs, the first indicating the talks based on their publishing date, then talks based on week day of publish, and talks based on month of publish. The months show no distinct trend. The days of the week indicates the majority of talks are posted on weekdays. 

```{r EDA published_date}
#published_date

TedRaw$published_date_clean <- anydate(TedRaw$published_date)

published_date_clean <- TedRaw %>%
  group_by(published_date_clean) %>%
  tally(name ="numTalks") 

ggplot(data = published_date_clean, aes(x = published_date_clean, y = numTalks))+
  geom_line(color = "#feb24c")+
  labs(x = "Date", y = "Count of TED Talks",
       title = "Talks by published date")

#day of week

TedRaw$published_date_wday <- wday(TedRaw$published_date_clean, label = TRUE)

published_date_wday <- TedRaw %>%
  group_by(published_date_wday) %>%
  tally(name ="numTalks") 

ggplot(data=published_date_wday, aes(x=published_date_wday, y=numTalks)) +
  #geom_point(stat = "identity", aes(color = '#2b8cbe'))+
  geom_bar(stat = "identity", fill = '#2b8cbe')+
  geom_text(aes(label = numTalks), vjust = 1.6, color = "white", size = 3)+
  labs(x = "Day of week", y = "Count of TED Talks",
       title = "Talks by published date (day of week)")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#month

TedRaw$published_date_month <- month(TedRaw$published_date_clean, label = TRUE)

published_date_month <- TedRaw %>%
  group_by(published_date_month) %>%
  tally(name ="numTalks") 

ggplot(data=published_date_month, aes(x=published_date_month, y=numTalks)) +
  #geom_point(stat = "identity", aes(color = '#2b8cbe'))+
  geom_bar(stat = "identity", fill = '#2b8cbe')+
  geom_text(aes(label = numTalks), vjust = 1.6, color = "white", size = 3)+
  labs(x = "Day of week", y = "Count of TED Talks",
       title = "Talks by published date (month)")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


Below we test for correlation and we can see that **published_date** is not correlated with views. In order to simplify we may want to keep **published_date** out of future models. 

```{r eda cor publisheddate}
ggscatter(TedRaw, x = "published_date_clean", y = "views", 
          add = "reg.line", conf.int = TRUE, color = "blue",
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "published date", ylab = "views")
```


### Variable: title
The variable **title** is the official title of the TED Talk. There are 2550 unique titles. Including the full title as a predictor really isn't worthwhile, but there may some common words that we could as as boolean predictors to our model. 


Below is a word frequency analysis on the title value. Outputted are the top 20 words. The majority of which would make good boolean predictors for future models. 
```{r EDA title, warning=FALSE}
title_corpus <- Corpus(VectorSource(TedRaw$title))

# Convert the text to lower case
title_corpus <- tm_map(title_corpus, content_transformer(tolower))
# Remove numbers
title_corpus <- tm_map(title_corpus, removeNumbers)
# Remove english common stopwords
title_corpus <- tm_map(title_corpus, removeWords, stopwords("english"))
# Remove punctuation
title_corpus <- tm_map(title_corpus, removePunctuation)

dtm_title <- TermDocumentMatrix(title_corpus)
m_title <- as.matrix(dtm_title)
v_title <- sort(rowSums(m_title),decreasing=TRUE)
d_title <- data.frame(word = names(v_title),freq=v_title)
head(d_title, 20)
```

### Variable: description
The variable **description** is a snippet of text summarizing what the talk is about. There are 2550 unique descriptions. Including the full description as a predictor really isn't feasible, but there may some common words that we could as as boolean predictors to our model. 


Below is a word frequency analysis on the description value. Outputted are the top 50 words. These words feel less like they capture the theme of the talk than the title, but a few might still make decent boolean predictors for future models. 
```{r EDA description, warning=FALSE}
############################################
#Work on finding frequency of the description column
############################################
description_corpus <- Corpus(VectorSource(TedRaw$description))

# Convert the text to lower case
description_corpus <- tm_map(description_corpus, content_transformer(tolower))
# Remove numbers
description_corpus <- tm_map(description_corpus, removeNumbers)
# Remove english common stopwords
description_corpus <- tm_map(description_corpus, removeWords, stopwords("english"))
# Remove punctuation
description_corpus <- tm_map(description_corpus, removePunctuation)

dtm_description <- TermDocumentMatrix(description_corpus)
m_description <- as.matrix(dtm_description)
v_description <- sort(rowSums(m_description),decreasing=TRUE)
d_description <- data.frame(word = names(v_description),freq=v_description)
head(d_description, 50)

```


### Variable: tags
The variable **tags** is a set of phrases that describe that talk. Each talk has a few tags associated with. Below is a word frequency analysis on the top 30 tags. These would likely make great boolean predictors since they appear fairly frequently amongst the dataset.  


```{r EDA tags, echo=TRUE, warning=FALSE}
TedRaw$tags <- TedRaw$tags %>%
  str_replace_all('\\[','') %>% 
  str_replace_all('\\]','')   %>% 
  str_replace_all("\\'",' ') %>% 
  str_replace_all(',',' ') %>% 
  tolower()

#talk_tags <- unnest_tokens(ted3,tags1,tags) %>% select(sno,tags1)
#datatable(head(talk_tags,10))

tags_corpus <- Corpus(VectorSource(TedRaw$tags))

# Remove punctuation
tags_corpus <- tm_map(tags_corpus, removePunctuation)
# Remove numbers
tags_corpus <- tm_map(tags_corpus, removeNumbers)
# Remove english common stopwords
tags_corpus <- tm_map(tags_corpus, removeWords, stopwords("english"))


dtm_tags <- TermDocumentMatrix(tags_corpus)
m_tags <- as.matrix(dtm_tags)
v_tags <- sort(rowSums(m_tags),decreasing=TRUE)
d_tags <- data.frame(word = names(v_tags),freq=v_tags)
head(d_tags, 30)

```

### Variable: main_speaker
The variable **main_speaker** contains the name of the speaker. There are 2156 unique speakers of the 2550 TED talks. Below is a graph showing the top 15 speakers by number of TED talks. This could be made a boolean predictor in a future model.

```{r EDA main_speaker, echo=TRUE}
main_speaker <- TedRaw %>%
  group_by(main_speaker) %>%
  tally(name ="numTalks") 

main_speaker <- arrange(main_speaker, desc(numTalks))
main_speakertop <- head(main_speaker,15)

ggplot(data=main_speakertop, aes(x=main_speaker, y=numTalks)) +
  #geom_point(stat = "identity", aes(color = '#2b8cbe'))+
  geom_bar(stat = "identity", fill = '#c51b8a')+
  geom_text(aes(label = numTalks), vjust = 1.6, color = "white", size = 3)+
  labs(x = "Speaker Name", y = "Count of TED Talks",
       title = "Talks by 15 most frequent speakers")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Variables not included
The following variables were removed from the dataset.  
**name** -- this contains duplicate information as it is the title and speaker combined.  
**ratings** -- too complex to parse left out for simplification.  
**related talks** -- this is a list of urls, it provides no meaning.  
**url** -- the url of the talk provides no meaning.  

## Data Transformation

Below is the code to tranform the data based on our findings in the EDA section. 
The following variables were removed: film_date, name, num_speaker, published_date, ratings, and related_talks. **title** was transformed to 20 boolean columns based on if the title contains the top 20 words. **tags** was transformed to 50 boolean columns based on if the talk contains some of the top 50 tags. **speaker_occupation** was transformed to 15 boolean columns representing if the occupation contains the top 15 occupations- note to catch more talks if the occupation was a part of another occupation it was considered (ex. singer/song writer is considered a writer).**main_speaker** was transformed to 15 boolean colums denoting if the talk was given by one of the 15 most frequent speakers.  **event** was transformed to 15 boolean columsn denoting if the talk happened at that event. **description** was transformed to 30 boolean columsn denoting if the talk description contains that word.  

```{r}
library(tidyverse)

TedRaw <- read.csv(file="ted_main.csv", header=TRUE, sep=",")

#comments(as is)
#duration (as is)
#languages (as is)
#views (as is)

TedRaw$film_date <- NULL
TedRaw$name <- NULL
TedRaw$num_speaker <- NULL
TedRaw$published_date <- NULL
TedRaw$ratings <- NULL
TedRaw$related_talks <- NULL
TedRaw$url <- NULL

####################
## title
##loop through top 20 words and create boolean columns for them

for(i in 1:20){
  col_name <- paste("tags",d_title$word[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(d_title$word[i], TedRaw$title, fixed = TRUE))
  
}

TedRaw$title <- NULL


####################
## tags
##loop through top 50 tags and create boolean columns for them

for(i in 1:50){
  col_name <- paste("tags",d_tags$word[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(d_tags$word[i], TedRaw$tags, fixed = TRUE))
  
}

TedRaw$tags <- NULL



####################
## for speaker_occupation
##loop through top 15 occupations and create boolean columns for them

for(i in 1:15){
  col_name <- paste("speaker_occupation",speaker_occupationtop$speaker_occupation[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(speaker_occupationtop$speaker_occupation[i], TedRaw$speaker_occupation, fixed = TRUE)
    )
  
}

TedRaw$speaker_occupation <- NULL


####################
## for main_speaker
##loop through top 15 speakers and create boolean columns for them

for(i in 1:15){
  col_name <- paste("speaker",main_speakertop$main_speaker[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(main_speakertop$main_speaker[i], TedRaw$main_speaker, fixed = TRUE))
  
}

TedRaw$main_speaker <- NULL


###################
# for event 
## loop through the top 20 events and create boolean columns for them

for(i in 1:20){
  col_name <- paste("event",eventtop$event[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(eventtop$event[i], TedRaw$event, fixed = TRUE))
  
}

TedRaw$event <- NULL



####################
## for description
##loop through top 30 description words and create boolean columns for them
for(i in 1:30){
  col_name <- paste("description",d_description$word[i], sep = "_")
  
  TedRaw <-  TedRaw %>%
    mutate(!!col_name := 
             grepl(d_description$word[i], TedRaw$description, fixed = TRUE))
  
}

TedRaw$description <- NULL

TedClean <- TedRaw %>% dplyr::rename_all(funs(make.names(.)))
```

## Building and evaluating Models
In order to understand what predictors influence the number of views the most we built a few different models.

### Linear Regression
Below are the results for the full linear regression model. 
```{r}
##Full linear regression model
set.seed(1)
summary(lm(views~., TedClean))
```


### Ridge Regression

First we built a ridge regression model with a really large lambda value. 

```{r ridge large lambda, message=FALSE, warning=FALSE}
library(glmnet)

set.seed(1)
data <-TedClean

y <- as.double(as.matrix(data$views)) # Only class
data$views <- NULL
x <- as.matrix(data) # Removes class

# Fitting the model (Ridge: Alpha = 0)
#select test and train data
set.seed(1)
train <- sample(1:nrow(x),nrow(x)/2)
test <- (-train)
y.test <- y[test]

ridge.mod <-glmnet(x[train,],y[train], alpha = 0)

#ridge regression with really large lambda
ridge.predlarge <- predict(ridge.mod,s=1e10,newx = x[test,])
#test MSE for large lambda
mean((ridge.predlarge-y.test)^2)
```

Ran ridge regression with cross-validation.

```{r Ridge with CV}
#ridge regression with cross validation

#first select best lambda
set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha = 0)
plot(cv.out)

bestlam <- cv.out$lambda.min
bestlam

#run with best lambda
ridge.pred <- predict(ridge.mod,s=bestlam,newx = x[test,])

#what is test MSE associeated with lambda = bestlam?
mean((ridge.pred -y.test)^2)
# so the test MSE decreased by half but it is still very large

```


Refit ridge regresion with the chosen lambda value.

```{r refit with chosen lambda ridge}
#Refit ridge regression model on the full data set with cv chosen lambda
set.seed(1)
out <- glmnet(x,y,alpha=0)
predict(out,type = "coefficients",s=bestlam)

##As expect none of the coefficients are zero and this is an highly uninterpretabe model.

```


### Lasso

Run lasso

```{r lasso}
library(glmnet)

set.seed(1)
data <- TedClean
y <- as.double(as.matrix(data$views)) # Only class
data$views <- NULL
x <- as.matrix(data) # Removes class


# Fitting the model (Ridge: Alpha = 0)
#select test and train data
set.seed(1)
train <- sample(1:nrow(x),nrow(x)/2)
test <- (-train)
y.test <- y[test]

lasso.mod <- glmnet(x[train,],y[train], alpha = 1)
plot(lasso.mod)

#perform cross validation with lasso
set.seed(1)
cv.outLasso <- cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.outLasso)

bestlamlasso <- cv.outLasso$lambda.min
lasso.pred <- predict(lasso.mod,bestlamlasso, newx=x[test,])
mean((lasso.pred - y.test)^2)
#lower test MSE that ridge regression with lambda chosen by cv
```

refit lasso  

```{r refit lasso model}
#refit lasso
set.seed(1)
outlasso <- glmnet(x,y,alpha=1)
lasso.coef <- predict(outlasso,type = "coefficients", s=bestlamlasso)
lasso.coef
```



### Bagging

```{r}
library(randomForest)

set.seed(1)
train <- sample(1:nrow(TedClean),nrow(TedClean)/2)
test <- (-train)

Ted.test <-TedClean[-train,"views"]

bag.Ted <- randomForest(views~., data=TedClean, subset = train,
                        mtry = 145, importance =T)
bag.Ted

#how does the bagged model (all predictors) perform on the test?
yhat.bag <- predict(bag.Ted,newdata=TedClean[-train,])
mean((yhat.bag -Ted.test)^2)

importance(bag.Ted)
varImpPlot(bag.Ted)
```



```{r}
# try random forest with p/3 variables
set.seed(1)
rf.Ted <- randomForest(views~., data=TedClean, subset = train,
                       importance = T)
yhat.rf <- predict(rf.Ted,newdata=TedClean[-train,])
#much lower MSE error, random forest showed an improvement over bagging
mean((yhat.rf-Ted.test)^2)

importance(rf.Ted)
varImpPlot(rf.Ted)

```


### Random Forest






















This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
